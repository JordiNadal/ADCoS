import json,urllib2
from datetime import datetime, timedelta

Sites = {"AUSTRALIA-ATLAS","CA-MCGILL-CLUMEQ-T2","CA-SCINET-T2","CA-VICTORIA-WESTGRID-T2","SFU-LCG2","TRIUMF-LCG2","TRIUMF-LCG2-MWTEST","CERN-PROD","CERN-TEST","CSCS-LCG2","CYFRONET-LCG2","DESY-HH","DESY-ZN","FMPHI-UNIBA","FZK-LCG2","FZU-IPV6","GOEGRID","HEPHY-UIBK","IEPSAS-KOSICE","LRZ-LMU","MAINZGRID","MPPMU","PRAGUELCG2","PRAGUELCG2-RUCIOTEST","PSNC","TUDRESDEN-ZIH","UNI-BONN","UNI-FREIBURG","UNI-SIEGEN-HEP","WUPPERTALPROD","EELA-UNLP","EELA-UTFSM","IFAE","IFIC-LCG2","LIP-COIMBRA","LIP-LISBON","NCG-INGRID-PT","PIC","UAM-LCG2","BEIJING-LCG2","GRIF","IN2P3-CC","IN2P3-CPPM","IN2P3-LAPP","IN2P3-LPC","IN2P3-LPSC","RO-02-NIPNE","RO-07-NIPNE","RO-14-ITIM","RO-16-UAIC","TOKYO-LCG2","GR-01-AUTH","INFN-BOLOGNA-T3","INFN-COSENZA","INFN-FRASCATI","INFN-GENOVA","INFN-LECCE","INFN-MILANO-ATLASC","INFN-NAPOLI-ATLAS","INFN-PAVIA","INFN-ROMA1","INFN-ROMA2","INFN-ROMA3","INFN-T1","INFN-TRIESTE","ZA-UJ","ZA-WITS-CORE","NDGF-T1","NDGF-T1-MWTEST","NDGF-T1-RUCIOTEST","NO-NORGRID-T2","SE-SNIC-T2","UNIBE-LHEP","UNICPH-NBI","UNIGE-DPNC","AM-04-YERPHI","IL-TAU-HEP","ITEP","JINR-LCG2","NIKHEF-ELPROD","RRC-KI","RU-MOSCOW-FIAN-LCG2","RU-PNPI","RU-PROTVINO-IHEP","SARA-MATRIX","TECHNION-HEP","TR-10-ULAKBIM","WEIZMANN-LCG2","RRC-KI-T1","TAIWAN-LCG2","RAL-LCG2","UKI-LT2-Brunel","UKI-LT2-IC-HEP","UKI-LT2-QMUL","UKI-LT2-QMUL-MWTEST","UKI-LT2-RHUL","UKI-LT2-UCL-HEP","UKI-NORTHGRID-LANCS-HEP","UKI-NORTHGRID-LIV-HEP","UKI-NORTHGRID-MAN-HEP","UKI-NORTHGRID-SHEF-HEP","UKI-SCOTGRID-DURHAM","UKI-SCOTGRID-ECDF","UKI-SCOTGRID-ECDF-MWTEST","UKI-SCOTGRID-GLASGOW","UKI-SOUTHGRID-BHAM-HEP","UKI-SOUTHGRID-CAM-HEP","UKI-SOUTHGRID-OX-HEP","UKI-SOUTHGRID-RALPP","UKI-SOUTHGRID-SUSX","AGLT2","ANLASC","BNL-ATLAS","BNL-OSG2","BU_ATLAS_TIER2","DUKE","LUCILLE","MWT2","MWT2_UC","NERSC","NEVIS","NYU-ATLAS","OUHEP","OU_OCHEP_SWT2","SBU","SLAC-ATLAS-T3","SMU","SWT2","SWT2_CPB","UPENN","UTA_SWT2","WISC","WT2"}

Tokens = {"DATADISK","PRODDISK","LOCALGROUPDISK"}
Link = "http://bourricot.cern.ch/dq2/deletion/search/?site=SITENAME_TOKENNAME&dataset=&state=&period=1&page=1&format=json"

SitesTobeReported = []

for site in Sites:
	for token in Tokens:
		tmp = Link.replace("SITENAME", site)
		query = tmp.replace("TOKENNAME",token)
		data = json.load(urllib2.urlopen(query))
		length_data = len(data)
		for i in range(0,length_data):
			if data[i]["fields"]["state_name"] == "Waiting": 
				creation_date = float(data[i]["fields"]["creationdate"].split(" ")[0].replace("-",""))
				if creation_date > (creation_date - 4): 
					if site+token not in SitesTobeReported:
						SitesTobeReported.append(site+token)

print SitesTobeReported
